{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "CPOXHysXKGLW"
   },
   "source": [
    "# \"Bach\" propagation through time\n",
    "\n",
    "    Thomas Moreau <thomas.moreau@inria.fr>\n",
    "    Mathurin Massias <mathurin.massias@inria.fr>\n",
    "\n",
    "Adapted from: [https://raphaellederman.github.io/articles/musicgeneration/](https://raphaellederman.github.io/articles/musicgeneration/)\n",
    "\n",
    "### Objective:\n",
    "\n",
    "- We will train a network to learn a **language model** and then use it to **generate new sequences**.\n",
    "\n",
    "- Instead of training the language model on text-documents (as it is the case in most examples on the web) we will train it to learn the language of the music of [Johann_Sebastian_Bach](https://en.wikipedia.org/wiki/Johann_Sebastian_Bach).\n",
    "For this, we will learn how J. S. Bach's \"Cello suite\" have been composed.\n",
    "Here is an example of a \"Cello suite\" [Link](https://www.youtube.com/watch?v=mGQLXRTl3Z0).\n",
    "\n",
    "- Rather than analyzing the audio signal, we use a symbolic representation of the \"Cello suite\" through their [MIDI files](https://en.wikipedia.org/wiki/MIDI#MIDI_files).\n",
    "  - A MIDI file encodes in a file, the set of musical notes, their duration, and intensity which have to be played by each instrument to \"render\" a musical piece. The \"rendering\" is usually operated by a MIDI synthesizer (such as VLC, QuickTime).\n",
    "\n",
    "- We will first train a language model on the whole set of MIDI files of the \"Cello suites\". \n",
    "- We will then sample this language model to create a new MIDI file which will be a brand new \"Cello suite\" composed by the computer.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RjlvVXvgbpbW"
   },
   "source": [
    "\n",
    "## Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IXocQU0HDntL"
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "from scipy.io import wavfile \n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import IPython  # to play audio sounds\n",
    "\n",
    "import pretty_midi  # to install with conda or pip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install pretty_midi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bgG1EmxKDhE5"
   },
   "source": [
    "## Collect data to create the language model\n",
    "\n",
    "We download the 36 MIDI files corresponding to the 36 \"Cello suites\" composed by J. S. Bach."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "id": "C9Tgx3ooDgSP",
    "outputId": "0f76ec00-6ead-46ca-bc3b-f6c370613151"
   },
   "outputs": [],
   "source": [
    "DATA_DIR = Path() / 'midi_bach'\n",
    "DATA_DIR.mkdir(exist_ok=True)\n",
    "\n",
    "import urllib.request\n",
    "list_midi_files = [\n",
    "    'cs1-2all.mid', 'cs5-1pre.mid', 'cs4-1pre.mid', 'cs3-5bou.mid',\n",
    "    'cs1-4sar.mid', 'cs2-5men.mid', 'cs3-3cou.mid', 'cs2-3cou.mid',\n",
    "    'cs1-6gig.mid', 'cs6-4sar.mid', 'cs4-5bou.mid', 'cs4-3cou.mid',\n",
    "    'cs5-3cou.mid', 'cs6-5gav.mid', 'cs6-6gig.mid', 'cs6-2all.mid',\n",
    "    'cs2-1pre.mid', 'cs3-1pre.mid', 'cs3-6gig.mid', 'cs2-6gig.mid',\n",
    "    'cs2-4sar.mid', 'cs3-4sar.mid', 'cs1-5men.mid', 'cs1-3cou.mid',\n",
    "    'cs6-1pre.mid', 'cs2-2all.mid', 'cs3-2all.mid', 'cs1-1pre.mid',\n",
    "    'cs5-2all.mid', 'cs4-2all.mid', 'cs5-5gav.mid', 'cs4-6gig.mid',\n",
    "    'cs5-6gig.mid', 'cs5-4sar.mid', 'cs4-4sar.mid', 'cs6-3cou.mid'\n",
    "]\n",
    "n_files = len(list_midi_files)\n",
    "for i, midiFile in enumerate(list_midi_files):\n",
    "    print(f\"Loading MIDI file {i:2} / {n_files}\\r\", end='', flush=True)\n",
    "    f_path = DATA_DIR / midiFile\n",
    "    if not f_path.exists():\n",
    "        urllib.request.urlretrieve(\"http://www.jsbach.net/midi/\" + midiFile, DATA_DIR / midiFile)\n",
    "        \n",
    "list_midi_files = list(DATA_DIR.glob(\"*.mid\"))\n",
    "n_files = len(list_midi_files)\n",
    "print(f\"Loaded {n_files} MIDI files in folder {DATA_DIR}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's first listen to a file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "midi_data = pretty_midi.PrettyMIDI(str(list_midi_files[0]))\n",
    "# Synthesize the resulting MIDI data using sine waves\n",
    "audio_data = midi_data.synthesize()\n",
    "IPython.display.Audio(audio_data, rate=44100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HgCE_6urcVsj"
   },
   "source": [
    "## Read and convert all MIDI files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mDofyEKjcd4E"
   },
   "source": [
    "We read all MIDI files and convert their content to one-hot-encoding matrix X_ohe of dimensions (T_x, n_x) where n_x is the number of possible musical notes.\n",
    "The duration of the sequences T_x can vary from one sequence to the other.\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_T_x = 1000  # maximum number of notes to consider in each file\n",
    "n_x = 79  # number of notes\n",
    "\n",
    "X_list = []\n",
    "\n",
    "for midi_file in list_midi_files:\n",
    "    # read the MIDI file\n",
    "    midi_data = pretty_midi.PrettyMIDI(str(midi_file))\n",
    "    notes_idx = [note.pitch for note in midi_data.instruments[0].notes]\n",
    "    # convert to one-hot-encoding\n",
    "    notes_idx = np.array(notes_idx[:max_T_x])\n",
    "    T_x = len(notes_idx)\n",
    "    X_ohe = np.zeros((T_x, n_x))\n",
    "    X_ohe[np.arange(T_x), notes_idx - 1] = 1\n",
    "    # add to the list  \n",
    "    X_list.append(X_ohe)\n",
    "    \n",
    "print(f\"We have {len(X_list)} MIDI tracks\")\n",
    "print(f\"The size of the first one is {X_list[0].shape}\")\n",
    "print(f\"The size of the second one is {X_list[1].shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist([x.shape[0] for x in X_list]);  # histogram of sizes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "nSf8RDL5cv7V"
   },
   "source": [
    "## Display the set of notes over time for a specific track "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 376
    },
    "colab_type": "code",
    "id": "wesPFMZHcvKG",
    "outputId": "a6f087cd-d55b-4153-9a10-18b094623d3b"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 6))\n",
    "plt.imshow(X_list[2].T[:, :100], aspect='auto')\n",
    "plt.set_cmap('gray_r')\n",
    "plt.grid(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's write a tiny function to play a track from its array representation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def play_from_array(X):\n",
    "    new_midi_data = pretty_midi.PrettyMIDI()\n",
    "    cello_program = pretty_midi.instrument_name_to_program('Cello')\n",
    "    cello = pretty_midi.Instrument(program=cello_program)\n",
    "    step = 0.3\n",
    "    for time_idx, note_number in enumerate(X.argmax(axis=-1)):\n",
    "        my_note = pretty_midi.Note(\n",
    "            velocity=100, pitch=note_number,\n",
    "            start=time_idx * step,\n",
    "            end=(time_idx+1) * step\n",
    "        )\n",
    "        cello.notes.append(my_note)\n",
    "    new_midi_data.instruments.append(cello)\n",
    "    audio_data = new_midi_data.synthesize()\n",
    "    return IPython.display.Audio(audio_data, rate=44100)\n",
    "\n",
    "play_from_array(X_list[2][:30])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "PMHtioR_c5y3"
   },
   "source": [
    "## Data conversion for the training of language model\n",
    "\n",
    "For each example/sequence and each possible starting note in this example/sequence, we create two sequences:\n",
    "- an input sequence: \n",
    "  - which contains a sub-sequence of length `sequence_length`;  this sub-sequence ranges from the note `t`\n",
    " to the note `t+sequence_length-1`\n",
    "- an output sequence:\n",
    "  - which contains the following note to be predicted, the one at position `t+sequence_length`\n",
    "\n",
    "The training is therefore performed by giving to the model a set of sequences as input and asking the network to predict each time the note that should come right after this sequence.\n",
    "\n",
    "Solution in `solutions/02-0_convert_data.py`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 663
    },
    "colab_type": "code",
    "id": "EGzvp4RCC0XX",
    "outputId": "c406ba40-a983-4ec7-d8e4-ae0be8fa01a9"
   },
   "outputs": [],
   "source": [
    "sequence_length = 20\n",
    "\n",
    "X_train_list = []\n",
    "y_train_list = []\n",
    "\n",
    "##########################\n",
    "# TODO\n",
    "\n",
    "# END TODO\n",
    "##########################\n",
    "\n",
    "X_train = np.asarray(X_train_list)\n",
    "y_train = np.asarray(y_train_list)\n",
    "\n",
    "print(\"X_train.shape:\", X_train.shape)\n",
    "print(\"y_train.shape:\", y_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HhNPrmvveuH3"
   },
   "source": [
    "# Training the language model\n",
    "\n",
    "The language model will be learned by training a RNN with input `X_train` and output `y_train`:  for each of the examples of sequences, we give to the network a sequence of notes of `sequence_length` duration, and ask the network to predict the following note of each sequence.\n",
    "\n",
    "The network will have the following structure\n",
    "- a layer of `LSTM` with $n_a$=256\n",
    "- a `Dense` layer with 256 units\n",
    "- a DropOut layer with rate 0.3 (the probability to \"drop-out\" one neuron is 0.3)\n",
    "- a `Dense` layer with a `softmax` activation which predict the probability of each of the $n_x$ notes as output\n",
    "\n",
    "Solution in `solutions/02-1_create_model.py`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 459
    },
    "colab_type": "code",
    "id": "epWHM4p6D5n7",
    "outputId": "f817b39f-ad02-4f18-86c7-759bce369930"
   },
   "outputs": [],
   "source": [
    "# create the model\n",
    "import torch\n",
    "\n",
    "\n",
    "class BachSynth(torch.nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        ###################\n",
    "        # TODO\n",
    "\n",
    "\n",
    "        # END TODO\n",
    "        ###################\n",
    "\n",
    "    def forward(self, X):\n",
    "        ###################\n",
    "        # TODO\n",
    "\n",
    "\n",
    "        # END TODO\n",
    "        ###################\n",
    "\n",
    "\n",
    "model = BachSynth()\n",
    "print(model)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's start the training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "colab_type": "code",
    "id": "yhWTNfIbFDmf",
    "outputId": "9d794a5d-b8f6-4c53-cd4c-a0c94aa3c908"
   },
   "outputs": [],
   "source": [
    "\n",
    "X_train = torch.tensor(X_train).float()\n",
    "y_train = torch.tensor(y_train)\n",
    "\n",
    "if not torch.cuda.is_available():\n",
    "    print(\"Training without GPU...\")\n",
    "    n_epochs = 2  # the bigger the better !\n",
    "    n_batches_per_epochs = 300  # the bigger the better !\n",
    "else:\n",
    "    print(\"Training with GPU...\")\n",
    "    n_epochs = 10  # the bigger the better !\n",
    "    n_batches_per_epochs = 1000  # the bigger the better !\n",
    "    \n",
    "    # move data and model to GPU.\n",
    "    X_train = X_train.cuda()\n",
    "    y_train = y_train.cuda()\n",
    "    model.cuda()\n",
    "\n",
    "# Define loss and optimizer\n",
    "loss = torch.nn.CrossEntropyLoss()\n",
    "opt = torch.optim.Adam(model.parameters())\n",
    "\n",
    "for e in range(n_epochs):\n",
    "    for i in range(n_batches_per_epochs):\n",
    "        idx = np.random.choice(len(X_train), size=64, replace=False)\n",
    "        opt.zero_grad()\n",
    "        y_pred = model(X_train[idx])[:, -1]\n",
    "        l = loss(y_pred, y_train[idx])\n",
    "        l.backward()\n",
    "        opt.step()\n",
    "        if i % 5 == 0:\n",
    "            print(f\"Epoch {e} - Iteration {i} - Loss = {l.item()}\\r\", end='', flush=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xM6g1YR3gtcO"
   },
   "source": [
    "# Generating a new sequence from sampling the language model\n",
    "\n",
    "To generate a new sequence from the language model, we simply give it as input a random sequence of duration `sequence_length` and ask the trained network to predict the output.\n",
    "\n",
    "The output of the network is a vector of probability of dimension $n_x$ which represents the probability of each note to be the next note of the melody given as input.\n",
    "\n",
    "From this vector, we select the note which has the maximum probability.\n",
    "\n",
    "We then concatenate this new note (its one-hot-encoding representation) at the end of the input sequence.\n",
    "We finally remove the first element of the input sequence to keep its duration constant (`sequence_length`).\n",
    "\n",
    "Instead of providing a random sequence as input, we rather randomly select one sequence out of the 2880 sequences used for training.\n",
    "We denote it by ```pattern```.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "_YHXTohsFGCX",
    "outputId": "698cac08-9aa2-4dab-e986-2a5ba5e4f1ea"
   },
   "outputs": [],
   "source": [
    "# --- select a random starting pattern\n",
    "rng = np.random.RandomState(42)\n",
    "start = rng.randint(0, len(X_train_list)-1)\n",
    "pattern = X_train[start][None, :, :].clone()\n",
    "print(start)\n",
    "print(pattern.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pat = pattern.detach().numpy()[0]\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.imshow(pat.T, aspect='auto')\n",
    "plt.plot(pat.argmax(axis=-1))\n",
    "plt.set_cmap('gray_r')\n",
    "plt.grid(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Solution in `solutions/02-2_generate_sequence.py`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "f_ADCs7uFW8m",
    "tags": []
   },
   "outputs": [],
   "source": [
    "T_y_generated = 200\n",
    "\n",
    "prediction_l = [p for p in pattern.detach().numpy()[0]]\n",
    "\n",
    "# generate T_y_generated notes\n",
    "for note_index in range(T_y_generated):\n",
    "    #######################\n",
    "    # TODO\n",
    "\n",
    "    # END TODO\n",
    "    #######################\n",
    "\n",
    "prediction_l = np.array(prediction_l)\n",
    "prediction_l.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "stQscvNOg0xd"
   },
   "source": [
    "### Display the generated sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 413
    },
    "colab_type": "code",
    "id": "c9IOPPiuLuHE",
    "outputId": "0009943c-a0a2-485e-f2e6-0830dfe86f87"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 6))\n",
    "plt.imshow(prediction_l.T, aspect='auto')\n",
    "plt.plot(prediction_l.argmax(axis=-1))\n",
    "plt.set_cmap('gray_r')\n",
    "plt.grid(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ZwM6osfDg5E0"
   },
   "source": [
    "### Listen to the generated sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8cpTszOFID51",
    "tags": []
   },
   "outputs": [],
   "source": [
    "play_from_array(prediction_l[:30])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sgjoIxEqL7bx"
   },
   "source": [
    "<div class=\"alert alert-success\">\n",
    "\n",
    "**Exercise**\n",
    "\n",
    "Insert after the first LSTM:\n",
    "  - a second layer of ```LSTM``` with $n_a$=256\n",
    "  - with a DropOut layer with rate 0.3 (the probability to \"drop-out\" one neuron is 0.3) between the 2 layers.\n",
    "\n",
    "Note that as we will stack two LSTM layers on top of each other (deep-RNN), we need to use the sequence output by the first LSTM at each time `t` as input the 2nd LSTM.\n",
    "</div>\n",
    "\n",
    "**HINT:** _No need to code, just read the doc of of the [LSTM class](https://pytorch.org/docs/stable/generated/torch.nn.LSTM.html)._\n",
    "\n",
    "Solution is in `solutions/02-2_layers_lstm.py`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Going Beyond\n",
    "\n",
    "Here, we are kind of cheating to reduce the size of the problem.\n",
    "Do you see why?\n",
    "\n",
    "<div class=\"alert alert-info\">\n",
    "\n",
    "**Answer:**\n",
    "\n",
    "We are not really using a RNN here as we only use fixed length sequences to train the model.\n",
    "We are learning a AR model such that:\n",
    "\n",
    "$$\n",
    "x_{t+k} = f_\\theta(x_t, \\dots x_{t+k-1})\n",
    "$$\n",
    "\n",
    "Here, the memory is not shared for successive prediction.\n",
    "\n",
    "To change this, one would need to train with varying length sequences, and to use \"_many-to-many_\" prediction but this is computationally heavy.\n",
    "See `scripts/traning_bach.py` for an example of RNN working directly on sequences.\n",
    "</div>\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "TPU",
  "colab": {
   "collapsed_sections": [],
   "name": "TP_RNN_Bach_simple.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
